{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "use CPU\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "from resnets import resnet50\n",
    "from data_utils import load_dataset\n",
    "\n",
    "# ------------------\n",
    "DATA_DIR = os.environ['DATA_DIR']\n",
    "MODELS_DIR = os.environ['MODELS_DIR']\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- LOADING DATASETS ----------------------\n",
    "trainloader, testloader = load_dataset('cifar100', DATA_DIR)\n",
    "\n",
    "\n",
    "# ---------------- SET GPU DEVICES ----------------------\n",
    "gpu_id = 0\n",
    "if torch.cuda.is_available() and use_gpu:  # checks whether a cuda gpu is available and whether the gpu flag is True\n",
    "\tif \",\" in gpu_id:\n",
    "\t\tdevice = [torch.device('cuda:{}'.format(idx)) for idx in gpu_id.split(\",\")]  # sets device to be cuda\n",
    "\telse:\n",
    "\t\tdevice = torch.device('cuda:{}'.format(gpu_id))  # sets device to be cuda\n",
    "\n",
    "\tos.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id  # sets the main GPU to be the one at index 0 (on multi gpu machines you can choose which one you want to use by using the relevant GPU ID)\n",
    "\tprint(\"use GPU\")\n",
    "\tprint(\"GPU ID {}\".format(gpu_id))\n",
    "else:\n",
    "\tprint(\"use CPU\")\n",
    "\tdevice = torch.device('cpu')  # sets the device to be CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Training the model\n",
    "# ------------------\n",
    "# -  Scheduling the learning rate\n",
    "# -  Saving the best model\n",
    "#\n",
    "# In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "# ``torch.optim.lr_scheduler``.\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\tsince = time.time()\n",
    "\n",
    "\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
    "\tbest_acc = 0.0\n",
    "\t\n",
    "\ttotal_trainset = len(trainloader.dataset)\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tlogging.info('Epoch: %d/%d' %(epoch, num_epochs));\n",
    "\n",
    "\t\tscheduler.step()\n",
    "\t\tmodel.train()  # Set model to training mode\n",
    "\n",
    "\t\ttrain_loss = 0\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\n",
    "\t\trunning_loss = 0.0\n",
    "\t\trunning_corrects = 0\n",
    "\n",
    "\t\t# Iterate over data.\n",
    "\t\tfor inputs, labels in trainloader:\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\toptimizer.zero_grad() # zero the parameter gradients\n",
    "\t\t\toutputs = model(inputs) # predictions\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# statistics\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\trunning_loss += loss.item() * inputs.size(0)\n",
    "\t\t\trunning_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\t\tepoch_loss = running_loss / total_trainset\n",
    "\t\tepoch_acc = running_corrects.double() / total_trainset\n",
    "\n",
    "\t\tlogging.info('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "\t\t\tphase, epoch_loss, epoch_acc))\n",
    "\n",
    "\t\t# deep copy the model\n",
    "\t\tif epoch_acc > best_acc:\n",
    "\t\t\tbest_acc = epoch_acc\n",
    "\t\t\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(state, os.path.join(MODELS_DIR, \n",
    "                                           \"transfer_learning\\ResNet_cifar10_to_100_Best.pwf\"))\n",
    "\n",
    "\ttime_elapsed = time.time() - since\n",
    "\tlogging.info('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "\t\ttime_elapsed // 60, time_elapsed % 60))\n",
    "\tlogging.info('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\t# load best model weights\n",
    "\tmodel.load_state_dict(best_model_wts)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Finetuning the convnet\n",
    "# ----------------------\n",
    "#\n",
    "\n",
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model = resnet50(pretrained=False)\n",
    "mdict = torch.load(os.path.join(MODELS_DIR, \"ResNet_cifar10/ResNet_cifar10_Best.pwf\"), map_location=device)['net']\n",
    "model.load_state_dict(mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "\tparam.requires_grad = False\n",
    "\t\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 100)\n",
    "\n",
    "###############################################\n",
    "############ Parallelize model ################\n",
    "if type(device) is list:\n",
    "\tmodel.to(device[0])\n",
    "\tmodel = nn.DataParallel(module=model, device_ids=device)\n",
    "\tdevice = device[0]\n",
    "else:\n",
    "\tmodel.to(device)  # sends the model from the cpu to the gpu\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Train and evaluate\n",
    "# ^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "\t\t\t\t\t   num_epochs=25)\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
